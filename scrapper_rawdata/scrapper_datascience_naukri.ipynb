{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract data from naukri.com (June 2023)\n",
    "\n",
    "\n",
    "Things to improve:\n",
    "- things to add : by-pass the cookie and policy option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/v313hjfd57bb0h0l_zx_wnt00000gn/T/ipykernel_4148/3182731978.py:28: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "# Author: Priti Gupta\n",
    "# Date: June 8th, 2023\n",
    "# Description: Scrapping data from Naukri to analyse salaries of data science positions in India\n",
    "# GitHub:https://github.com/PritiG1/DS-SalaryPredictor\n",
    "\n",
    "\n",
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def scraper_naukri(keyword_job):\n",
    "    \"\"\"\n",
    "    Function to scrape job data from Naukri website based on a given job keyword.\n",
    "    \"\"\"\n",
    "    # Encode the keyword for URL compatibility\n",
    "    keyword_job_encoded = urllib.parse.quote(keyword_job, safe='-')\n",
    "    \n",
    "    # Construct the URL with the encoded keyword\n",
    "    url = 'https://www.naukri.com/data-scientist-jobs-in-india-?k=' + keyword_job_encoded + '&l=india&nignbevent_src=jobsearchDeskGNB'\n",
    "\n",
    "    # Specify the path to the Chrome WebDriver\n",
    "    path = '/Users/pritigupta/Desktop/chromedriver_mac64/chromedriver'\n",
    "    \n",
    "    # Create a Chrome WebDriver instance\n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    # Open the URL in the WebDriver\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load (sleep for 15 seconds)\n",
    "    time.sleep(15)\n",
    "\n",
    "    # Check if the CSV file is empty to determine column names\n",
    "    with open('datascientist_salary_naukri.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        file_empty = csvfile.tell() == 0\n",
    "        if file_empty:\n",
    "            column_names = ['Title', 'Company', 'Experience', 'Location', 'Salary']\n",
    "        else:\n",
    "            column_names = next(reader)\n",
    "\n",
    "    # Open the CSV file in append mode to write job data\n",
    "    with open('datascientist_salary_naukri.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write column names if the file is empty\n",
    "        if file_empty:\n",
    "            writer.writerow(column_names)\n",
    "\n",
    "        # Iterate over job pages (up to 489 pages)\n",
    "        for _ in range(1, 490):\n",
    "            # Find all job elements on the page\n",
    "            all_jobs = driver.find_elements(By.XPATH, '//section[@class=\"listContainer fleft\"]')\n",
    "\n",
    "            # Iterate over each job element\n",
    "            for job in all_jobs:\n",
    "                job_elements = job.find_elements(By.XPATH, './/article[@class=\"jobTuple\"]')\n",
    "                for element in job_elements:\n",
    "                    try:\n",
    "                        # Extract job details (title, company, experience, location, salary) and write to CSV file\n",
    "                        writer.writerow([\n",
    "                            element.find_element(By.XPATH, './/a[@class=\"title ellipsis\"]').text,\n",
    "                            element.find_element(By.XPATH, './/a[@class=\"subTitle ellipsis fleft\"]').text,\n",
    "                            element.find_element(By.XPATH, './/span[@class=\"ellipsis fleft expwdth\"]').text,\n",
    "                            element.find_element(By.XPATH, './/span[@class=\"ellipsis fleft locWdth\"]').text,\n",
    "                            element.find_element(By.XPATH, './/span[@class=\"ellipsis fleft \"]').text\n",
    "                        ])\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "        \n",
    "            # Wait for the \"Next\" button to be clickable\n",
    "            wait = WebDriverWait(driver, 15)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.XPATH,'.//a[@class=\"fright fs14 btn-secondary br2\"]')))\n",
    "            \n",
    "            # Click the \"Next\" button\n",
    "            next_button.click()\n",
    "            \n",
    "            # Wait for the page to load (sleep for 15 seconds)\n",
    "            time.sleep(15)\n",
    "\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Return True to indicate successful execution\n",
    "    return True\n",
    "\n",
    "# Call the scraper function with the desired job keyword\n",
    "data = scraper_naukri('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datascientist_salary_naukri.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee4f3c9c65d0652fa8a516c7950688c3bdccdf1bea46082d435231cdb2b311eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
