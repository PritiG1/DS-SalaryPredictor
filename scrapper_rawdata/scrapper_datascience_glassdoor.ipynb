{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract data from glassdoor (June 2023)\n",
    "\n",
    "\n",
    "Things to improve:\n",
    "- create new file by itself, if does not exist in the dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/v313hjfd57bb0h0l_zx_wnt00000gn/T/ipykernel_4799/3630054829.py:36: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "# Author: Priti Gupta\n",
    "# Date: June 8th, 2023\n",
    "# Description: Scrapping data from glassdoor to analyse salaries of data science positions in India\n",
    "# GitHub: https://github.com/PritiG1/DS-SalaryPredictor\n",
    "\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "def text_clean(string):\n",
    "    \"\"\"\n",
    "    Function to clean the text by removing a specific pattern using regular expressions.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\d+(\\.\\d+)? ★$\"  # Regex pattern to match the substring \"3.9 ★\" at the end of the string\n",
    "    stripped_string = re.sub(pattern, \"\", string)  # Remove the matched substring using regex substitution\n",
    "    return stripped_string\n",
    "\n",
    "def scraper_naukri(keyword_job):\n",
    "    \"\"\"\n",
    "    Function to scrape job data from Glassdoor website based on a given job keyword.\n",
    "    \"\"\"\n",
    "    # Encode the keyword for URL compatibility\n",
    "    keyword_job_encoded = urllib.parse.quote(keyword_job, safe='-')\n",
    "\n",
    "    # Construct the URL with the encoded keyword\n",
    "    url = 'https://www.glassdoor.co.in/Job/india-' + keyword_job_encoded + '-jobs-SRCH_IL.0,5_IN115_KO6,20.htm?includeNoSalaryJobs=true'\n",
    "    \n",
    "    # Specify the path to the Chrome WebDriver\n",
    "    path = '/Users/pritigupta/Desktop/chromedriver_mac64/chromedriver'\n",
    "    \n",
    "    # Create a Chrome WebDriver instance\n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    # Open the URL in the WebDriver\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load (sleep for 15 seconds)\n",
    "    time.sleep(15)\n",
    "\n",
    "    # Check if the CSV file is empty to determine column names\n",
    "    with open('datascientist_salary_glassdoor.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        file_empty = csvfile.tell() == 0\n",
    "        if file_empty:\n",
    "            column_names = ['Title', 'Company', 'Location', 'Salary']\n",
    "        else:\n",
    "            column_names = next(reader)\n",
    "\n",
    "    # Open the CSV file in append mode to write job data\n",
    "    with open('datascientist_salary_glassdoor.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write column names if the file is empty\n",
    "        if file_empty:\n",
    "            writer.writerow(column_names)\n",
    "\n",
    "        # Iterate over job pages (up to 28 pages)\n",
    "        for _ in range(1, 29):\n",
    "            # Find all job elements on the page\n",
    "            all_jobs = driver.find_elements(By.XPATH, '//article[@id=\"MainCol\"]')\n",
    "\n",
    "            # Iterate over each job element\n",
    "            for job in all_jobs:\n",
    "                job_elements = job.find_elements(By.XPATH, './/li[@class=\"react-job-listing css-1kjejvf eigr9kq3\"]')\n",
    "                for element in job_elements:\n",
    "                    try:\n",
    "                        # Extract job details (company, title, location, salary) and write to CSV file\n",
    "                        company_name = element.find_element(By.XPATH, './/div[@class=\"d-flex align-items-center\"][1]').text\n",
    "                        writer.writerow([\n",
    "                            element.find_element(By.XPATH, './/div[@class=\"job-title mt-xsm\"]').text,\n",
    "                            text_clean(company_name),\n",
    "                            element.find_element(By.XPATH, './/div[@class=\"location mt-xxsm\"]').text,\n",
    "                            element.find_element(By.XPATH, './/div[@class=\"salary-estimate\"]').text\n",
    "                        ])\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "        \n",
    "            # Wait for the \"Next\" button to be clickable\n",
    "            wait = WebDriverWait(driver, 15)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.XPATH, './/button[@class=\"nextButton job-search-1iiwzeb e13qs2072\"]')))\n",
    "            \n",
    "            # Click the \"Next\" button\n",
    "            next_button.click()\n",
    "            \n",
    "            # Wait for the page to load (sleep for 10 seconds)\n",
    "            time.sleep(10)\n",
    "            \n",
    "            # Check for and close any pop-up windows\n",
    "            try:\n",
    "                pop_up = driver.find_element(By.XPATH, './/span[@class=\"SVGInline modal_closeIcon\"]')\n",
    "                pop_up.click()\n",
    "                time.sleep(2)\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Return True to indicate successful execution\n",
    "    return True\n",
    "\n",
    "# Call the scraper function with the desired job keyword\n",
    "data = scraper_naukri('Data Scientist')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee4f3c9c65d0652fa8a516c7950688c3bdccdf1bea46082d435231cdb2b311eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
